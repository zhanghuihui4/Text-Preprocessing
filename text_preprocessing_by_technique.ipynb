{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e636313f",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a2526d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = \"&&& ^@@^ 11111     Hey! did you know that the summer      break is coming? Amazing right!! It's only 5 more days!! Let's go hiking! I'd like to know how do you think about it!\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a329e30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&&& ^@@^ hey, did you know that the summer break is coming? amazing right!! it’s only 5 more days!! let’s go hiking!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lowercasing\n",
    "lower_txt = sample_txt.lower()\n",
    "lower_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5153393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Hey did you know that the summer break is coming Amazing right It’s only 5 more days Let’s go hiking'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Removing Punctuation\n",
    "### There are multiple ways to remove punctuations\n",
    "\n",
    "# Opeion 1 （it cannot deal with non-English punctuations)\n",
    "import string\n",
    "punc_removed = sample_txt.translate(str.maketrans('', '', string.punctuation))\n",
    "punc_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22279be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Hey did you know that the summer break is coming Amazing right Its only 5 more days Lets go hiking'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2\n",
    "import re\n",
    "punc_removed = re.sub(r'[^\\w\\s]', '', sample_txt)\n",
    "punc_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0e0069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Hey did you know that the summer break is coming Amazing right Its only 5 more days Lets go hiking'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 3\n",
    "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~’‘”“'''\n",
    "punc_removed = [s for s in sample_txt if s not in punc ]\n",
    "punc_removed = ''.join(p for p in punc_removed)\n",
    "punc_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb6f346e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&&& ^@@^  Hey, did you know that the summer break is coming? Amazing right!! It’s only  more days!! Let’s go hiking!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Removing numbers\n",
    "\n",
    "# Option 1\n",
    "import string\n",
    "translation_table = str.maketrans('', '', string.digits)\n",
    "num_removed = sample_txt.translate(translation_table)\n",
    "num_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7982002a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&&& ^@@^  Hey, did you know that the summer break is coming? Amazing right!! It’s only  more days!! Let’s go hiking!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2\n",
    "import re\n",
    "pattern = r'[0-9]'\n",
    "num_removed = re.sub(pattern,'',sample_txt)\n",
    "num_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b25eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"&&& ^@@^  Hey! did you know that the summer break is coming? Amazing right!! It's only  more days!! Let's go hiking! I'd like to know how do you think about it!\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 3\n",
    "num_removed = ''.join((s for s in sample_txt if not s.isdigit()))\n",
    "num_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30ad0981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&&& ^@@^ 11111 Hey, did you know that the summer break is coming? Amazing right!! It is only 5 more days!! Let us go hiking! I would like to know how do you think about it!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Expanding contractions\n",
    "\n",
    "import contractions\n",
    "contr_expanded = contractions.fix(sample_txt)\n",
    "contr_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a082e498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"&&& ^@@^ 11111 Hey! did you know that the summer break is coming? Amazing right!! It's only 5 more days!! Let's go hiking! I'd like to know how do you think about it!\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Removing extra white spaces\n",
    "\n",
    "wt_space_removed = ' '.join(s for s in sample_txt.split())\n",
    "wt_space_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "178abdca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'did',\n",
       " 'you',\n",
       " 'know',\n",
       " 'that',\n",
       " 'the',\n",
       " 'summer',\n",
       " 'break',\n",
       " 'is',\n",
       " 'coming',\n",
       " 'amazing',\n",
       " 'right',\n",
       " 'its',\n",
       " 'only',\n",
       " 'more',\n",
       " 'days',\n",
       " 'let',\n",
       " 'us',\n",
       " 'go',\n",
       " 'hiking',\n",
       " 'id',\n",
       " 'like',\n",
       " 'to',\n",
       " 'know',\n",
       " 'how',\n",
       " 'do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'about',\n",
       " 'it']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Transfering a cleaned sentence to a list of words will make the following steps easier\n",
    "### Because the following steps are exected at the word level\n",
    "\n",
    "lower_txt = sample_txt.lower()\n",
    "punc_removed = re.sub(r'[^\\w\\s]', '', lower_txt)\n",
    "num_removed = ''.join((s for s in punc_removed if not s.isdigit()))\n",
    "contr_expanded = contractions.fix(num_removed)\n",
    "wt_space_removed = ' '.join(s for s in contr_expanded.split())\n",
    "\n",
    "word_lst = [w for w in wt_space_removed.split()]\n",
    "word_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15bf35",
   "metadata": {},
   "source": [
    "# Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a19ba129",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'know',\n",
       " 'summer',\n",
       " 'break',\n",
       " 'coming',\n",
       " 'amazing',\n",
       " 'right',\n",
       " 'days',\n",
       " 'let',\n",
       " 'us',\n",
       " 'hiking',\n",
       " 'id',\n",
       " 'like',\n",
       " 'know',\n",
       " 'think']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "# you can expand the stopwords list:\n",
    "en_stopwords += ['go','day']\n",
    "\n",
    "stw_removed = [s for s in word_lst if s.lower() not in en_stopwords]\n",
    "stw_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f8f42",
   "metadata": {},
   "source": [
    "# Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "708e5ec3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'did',\n",
       " 'you',\n",
       " 'know',\n",
       " 'that',\n",
       " 'the',\n",
       " 'summer',\n",
       " 'break',\n",
       " 'is',\n",
       " 'come',\n",
       " 'amaz',\n",
       " 'right',\n",
       " 'it',\n",
       " 'onli',\n",
       " 'more',\n",
       " 'day',\n",
       " 'let',\n",
       " 'us',\n",
       " 'go',\n",
       " 'hike',\n",
       " 'id',\n",
       " 'like',\n",
       " 'to',\n",
       " 'know',\n",
       " 'how',\n",
       " 'do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'about',\n",
       " 'it']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stemmed_word_lst = [ps.stem(w) for w in word_lst]\n",
    "stemmed_word_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "605bb3a3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\zhang\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'did',\n",
       " 'you',\n",
       " 'know',\n",
       " 'that',\n",
       " 'the',\n",
       " 'summer',\n",
       " 'break',\n",
       " 'is',\n",
       " 'coming',\n",
       " 'amazing',\n",
       " 'right',\n",
       " 'it',\n",
       " 'only',\n",
       " 'more',\n",
       " 'day',\n",
       " 'let',\n",
       " 'u',\n",
       " 'go',\n",
       " 'hiking',\n",
       " 'id',\n",
       " 'like',\n",
       " 'to',\n",
       " 'know',\n",
       " 'how',\n",
       " 'do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'about',\n",
       " 'it']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wnl = WordNetLemmatizer()\n",
    "lemmatized_word_lst = [wnl.lemmatize(w) for w in word_lst]\n",
    "lemmatized_word_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32cdd3",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9d01861",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['&',\n",
       "  '&',\n",
       "  '&',\n",
       "  '^',\n",
       "  '@',\n",
       "  '@',\n",
       "  '^',\n",
       "  '11111',\n",
       "  'Hey',\n",
       "  '!',\n",
       "  'did',\n",
       "  'you',\n",
       "  'know',\n",
       "  'that',\n",
       "  'the',\n",
       "  'summer',\n",
       "  'break',\n",
       "  'is',\n",
       "  'coming',\n",
       "  '?',\n",
       "  'Amazing',\n",
       "  'right',\n",
       "  '!',\n",
       "  '!',\n",
       "  'It',\n",
       "  \"'s\",\n",
       "  'only',\n",
       "  '5',\n",
       "  'more',\n",
       "  'days',\n",
       "  '!',\n",
       "  '!',\n",
       "  'Let',\n",
       "  \"'s\",\n",
       "  'go',\n",
       "  'hiking',\n",
       "  '!',\n",
       "  'I',\n",
       "  \"'d\",\n",
       "  'like',\n",
       "  'to',\n",
       "  'know',\n",
       "  'how',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'about',\n",
       "  'it',\n",
       "  '!'],\n",
       " ['hey',\n",
       "  'did',\n",
       "  'you',\n",
       "  'know',\n",
       "  'that',\n",
       "  'the',\n",
       "  'summer',\n",
       "  'break',\n",
       "  'is',\n",
       "  'coming',\n",
       "  'amazing',\n",
       "  'right',\n",
       "  'its',\n",
       "  'only',\n",
       "  'more',\n",
       "  'days',\n",
       "  'let',\n",
       "  'us',\n",
       "  'go',\n",
       "  'hiking',\n",
       "  'id',\n",
       "  'like',\n",
       "  'to',\n",
       "  'know',\n",
       "  'how',\n",
       "  'do',\n",
       "  'you',\n",
       "  'think',\n",
       "  'about',\n",
       "  'it'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Note: if we don't remove punctuations or numbers in advance, they will also be tokenized\n",
    "tokenized = word_tokenize(sample_txt)\n",
    "tokenized_clean = word_tokenize(' '.join(w for w in word_lst))\n",
    "tokenized,tokenized_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec84ec1",
   "metadata": {},
   "source": [
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "37f9f3d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('&', 'CC'),\n",
       " ('&', 'CC'),\n",
       " ('&', 'CC'),\n",
       " ('^', 'NNP'),\n",
       " ('@', 'NNP'),\n",
       " ('@', 'NNP'),\n",
       " ('^', 'VBD'),\n",
       " ('11111', 'CD'),\n",
       " ('Hey', 'NNP'),\n",
       " ('!', '.'),\n",
       " ('did', 'VBD'),\n",
       " ('you', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('summer', 'NN'),\n",
       " ('break', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('coming', 'VBG'),\n",
       " ('?', '.'),\n",
       " ('Amazing', 'VBG'),\n",
       " ('right', 'RB'),\n",
       " ('!', '.'),\n",
       " ('!', '.'),\n",
       " ('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('only', 'RB'),\n",
       " ('5', 'CD'),\n",
       " ('more', 'JJR'),\n",
       " ('days', 'NNS'),\n",
       " ('!', '.'),\n",
       " ('!', '.'),\n",
       " ('Let', 'VB'),\n",
       " (\"'s\", 'POS'),\n",
       " ('go', 'VB'),\n",
       " ('hiking', 'NN'),\n",
       " ('!', '.'),\n",
       " ('I', 'PRP'),\n",
       " (\"'d\", 'MD'),\n",
       " ('like', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('know', 'VB'),\n",
       " ('how', 'WRB'),\n",
       " ('do', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('think', 'VB'),\n",
       " ('about', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "word_tokens = word_tokenize(sample_txt)\n",
    "pos_tagged = nltk.pos_tag(word_tokens)\n",
    "pos_tagged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
